---
title: "QUENTIN PETITJEAN"
image: images/Home_QP.png
favicon: images/FavIcon.png
twitter:
  creator: "@Q_PETITJEAN"
  site: "@Q_PETITJEAN"
links:
  - label: '<i class="fa fa-envelope"></i>'
    url: "mailto:q.petitjean1@gmail.com"
  - label: '<i class="fa fa-github"></i>'
    url: "https://github.com/qpetitjean"
  - label: '<i class="fa fa-twitter"></i>'
    url: "https://twitter.com/Q_PETITJEAN"
  - label: '<i class="ai ai-orcid fa-lg"></i>'
    url: "https://orcid.org/0000-0003-2708-7831"
  - label: '<i class="ai ai-researcherid fa-lg"></i>'
    url: "https://www.webofscience.com/wos/author/record/AAE-8204-2021"
  - label: '<i class="ai ai-researchgate fa-lg"></i>'
    url: "https://www.researchgate.net/profile/Quentin-Petitjean-2"
  - label: '<i class="ai ai-google-scholar fa-lg"></i>'
    url: "https://scholar.google.com/citations?user=GMudi1sAAAAJ&hl=en"
site: distill::distill_website
output:
  postcards::trestles
  
---

```{r metadata, include=FALSE, results='asis'}
  metathis::meta_social(
    metathis::meta(),
    title = "Quentin PETITJEAN webpage",
    description = "The personal website of Quentin PETITJEAN",
    url = "https://github.com/qpetitjean",
    image = "images/Home_QP.png",
    image_alt = "A photo of Quentin PETITJEAN",
    og_type = "website",
    og_author = "Quentin PETITJEAN",
    twitter_card_type = "summary",
    twitter_creator = "@Q_PETITJEAN"
  )
```

```{r worldCloud, message=FALSE, warning=FALSE, include=FALSE}
if(!require(wordcloud)){
  install.packages("wordcloud")
}
if(!require(tm)){
  install.packages("tm")
}
if(!require(RColorBrewer)){
  install.packages("RColorBrewer")
}
  
pdfList <-
  list.files(
    "PubList",
    pattern = ".pdf",
    full.names = TRUE
  )

AllPub <- c()
for (i in seq(length(pdfList))) {
  fullPub <- pdftools::pdf_text(pdf = pdfList[i])
  
  # concatenate all pages
  fullPub <- paste(fullPub, collapse = "")
  
  # keep only the text between the Introduction and the Acknowledgements
  NorefNoAbs <- substr(
    fullPub,
    regexpr("Introduction",
            fullPub, perl = F)[1],
    regexpr("Acknowledgements",
            fullPub, perl = F)[1]
  )
  
  # remove past and plural form (ed and s)
  docs <-
    gsub(
      "(?<![aei])([ie][d])(?=[^a-zA-Z])|(?<=[ertkgwmnl])s(?=[^a-zA-Z])",
      "",
      NorefNoAbs,
      perl = T
    )
  
  # remove every strings between brackets (mainly references)
  docs <- gsub("\\(.*?\\)", "", docs, perl = T)
  
  # keep only alphanumeric character (remove special characters)
  docs <-
    gsub("[^[:alnum:]]",
         " ",
         docs,
         perl = T)
  
  # remove all numbers
  docs <- gsub("[[:digit:]]+", "", docs)
  
  AllPub <- c(AllPub, docs)
  AllPub <- paste(AllPub, collapse = "")
}

# create a corpus (needed for the following functions)
docs <- tm::Corpus(tm::VectorSource(AllPub))
#tm::inspect(docs)

# Convert the text to lowercase
docs <- tm::tm_map(docs, tm::content_transformer(tolower))

# remove empty english words
docs <- tm::tm_map(docs, tm::removeWords, tm::stopwords("english"))

# remove english prepositions
docs <-
  tm::tm_map(
    docs,
    tm::removeWords,
    c(
      "aboard",
      "about",
      "above",
      "across",
      "after",
      "against",
      "along",
      "amid",
      "among",
      "anti",
      "around",
      "as",
      "at",
      "before",
      "behind",
      "below",
      "beneath",
      "beside",
      "besides",
      "between",
      "beyond",
      "but",
      "by",
      "concerning",
      "considering",
      "despite",
      "down",
      "during",
      "except",
      "excepting",
      "excluding",
      "following",
      "for",
      "from",
      "in",
      "inside",
      "into",
      "like",
      "minus",
      "near",
      "of",
      "off",
      "on",
      "onto",
      "opposite",
      "outside",
      "over",
      "past",
      "per",
      "plus",
      "regarding",
      "round",
      "save",
      "since",
      "than",
      "through",
      "to",
      "toward",
      "towards",
      "under",
      "underneath",
      "unlike",
      "until",
      "up",
      "upon",
      "versus",
      "via",
      "with",
      "within",
      "without"
    )
  )

# remove english adjectives
docs <-
  tm::tm_map(
    docs,
    tm::removeWords,
    c(
      "abundant",
      "accurate",
      "addicted",
      "adorable",
      "adventurous",
      "afraid",
      "aggressive",
      "alcoholic",
      "alert",
      "aloof",
      "ambitious",
      "ancient",
      "angry",
      "animated",
      "annoying",
      "anxious",
      "arrogant",
      "ashamed",
      "attractive",
      "auspicious",
      "awesome",
      "awful",
      "abactinal",
      "abandoned",
      "abashed",
      "abatable",
      "abatic",
      "abaxial",
      "abbatial",
      "abbreviated",
      "abducent",
      "abducting",
      "aberrant",
      "abeyant",
      "abhorrent",
      "abiding",
      "abient",
      "bad",
      "bashful",
      "beautiful",
      "belligerent",
      "beneficial",
      "best",
      "big",
      "bitter",
      "bizarre",
      "black",
      "blue",
      "boring",
      "brainy",
      "bright",
      "broad",
      "broken",
      "busy",
      "barren",
      "barricaded",
      "barytic",
      "basal",
      "basaltic",
      "baseborn",
      "based",
      "baseless",
      "basic",
      "bathyal",
      "battleful",
      "battlemented",
      "batty",
      "batwing",
      "bias",
      "calm",
      "capable",
      "careful",
      "careless",
      "caring",
      "cautious",
      "charming",
      "cheap",
      "cheerful",
      "chubby",
      "clean",
      "clever",
      "clumsy",
      "cold",
      "colorful",
      "comfortable",
      "concerned",
      "confused",
      "crowded",
      "cruel",
      "curious",
      "curly",
      "cute",
      "damaged",
      "dangerous",
      "dark",
      "deep",
      "defective",
      "delicate",
      "delicious",
      "depressed",
      "determined",
      "different",
      "dirty",
      "disgusting",
      "dry",
      "dusty",
      "daft",
      "daily",
      "dainty",
      "damn",
      "damning",
      "damp",
      "dampish",
      "darkling",
      "darned",
      "dauntless",
      "daylong",
      "early",
      "educated",
      "efficient",
      "elderly",
      "elegant",
      "embarrassed",
      "empty",
      "encouraging",
      "enthusiastic",
      "excellent",
      "exciting",
      "expensive",
      "fabulous",
      "fair",
      "faithful",
      "famous",
      "fancy",
      "fantastic",
      "fast",
      "fearful",
      "fearless",
      "fertile",
      "filthy",
      "foolish",
      "forgetful",
      "friendly",
      "funny",
      "gentle",
      "glamorous",
      "glorious",
      "gorgeous",
      "graceful",
      "grateful",
      "great",
      "greedy",
      "green",
      "handsome",
      "happy",
      "harsh",
      "healthy",
      "heavy",
      "helpful",
      "hilarious",
      "historical",
      "horrible",
      "hot",
      "huge",
      "humorous",
      "hungry",
      "ignorant",
      "illegal",
      "imaginary",
      "impolite",
      "important",
      "impossible",
      "innocent",
      "intelligent",
      "interesting",
      "jealous",
      "jolly",
      "juicy",
      "juvenile",
      "kind",
      "large",
      "legal",
      "light",
      "literate",
      "little",
      "lively",
      "lonely",
      "loud",
      "lovely",
      "macho",
      "magical",
      "magnificent",
      "massive",
      "mature",
      "mean",
      "messy",
      "modern",
      "narrow",
      "nasty",
      "naughty",
      "nervous",
      "new",
      "noisy",
      "nutritious",
      "obedient",
      "obese",
      "obnoxious",
      "old",
      "overconfident",
      "peaceful",
      "pink",
      "polite",
      "poor",
      "powerful",
      "precious",
      "pretty",
      "proud",
      "quick",
      "quiet",
      "rapid",
      "rare",
      "red",
      "remarkable",
      "responsible",
      "rich",
      "romantic",
      "royal",
      "rude",
      "scintillating",
      "secretive",
      "selfish",
      "serious",
      "sharp",
      "shiny",
      "shocking",
      "short",
      "shy",
      "silly",
      "sincere",
      "skinny",
      "slim",
      "slow",
      "small",
      "soft",
      "spicy",
      "spiritual",
      "splendid",
      "strong",
      "successful",
      "sweet",
      "talented",
      "tall",
      "tense",
      "terrible",
      "terrific",
      "thick",
      "thin",
      "tiny",
      "tactful",
      "tailor-made",
      "take-charge",
      "tangible",
      "tasteful",
      "tasty",
      "teachable",
      "teeming",
      "tempean",
      "temperate",
      "tenable",
      "tenacious",
      "tender",
      "tender-hearted",
      "terrific",
      "testimonial",
      "thankful",
      "thankworthy",
      "therapeutic",
      "thorough",
      "thoughtful",
      "ugly",
      "unique",
      "untidy",
      "upset",
      "victorious",
      "violent",
      "vulgar",
      "warm",
      "weak",
      "wealthy",
      "wide",
      "wise",
      "witty",
      "wonderful",
      "worried",
      "young",
      "youthful",
      "zealous"
    )
  )

# remove english adverbs
docs <-
  tm::tm_map(
    docs,
    tm::removeWords,
    c(
      "hence",
      "therefore",
      "thus",
      "accordingly",
      "significantly",
      "indeed",
      "finally",
      "however",
      "thereby",
      "consequently",
      "subsequently",
      "indeed",
      "now",
      "nevertheless",
      "nonetheless",
      "above",
      "behind",
      "below",
      "on",
      "down",
      "up",
      "far",
      "in",
      "outside",
      "towards",
      "under",
      "upstairs",
      "back",
      "over",
      "away",
      "off",
      "before",
      "later",
      "since",
      "soon",
      "still",
      "yet",
      "early",
      "earlier",
      "eventually",
      "recently",
      "previously",
      "finally",
      "yesterday",
      "today",
      "tomorrow",
      "tonight",
      "now",
      "then",
      "this morning",
      "abnormally",
      "abruptly",
      "absently",
      "accidentally",
      "accusingly",
      "actually",
      "adventurously",
      "adversely",
      "afterwards",
      "almost",
      "always",
      "amazingly",
      "angrily",
      "anxiously",
      "arrogantly",
      "awkwardly",
      "badly",
      "bashfully",
      "beautifully",
      "bitterly",
      "bleakly",
      "blindly",
      "blissfully",
      "boldly",
      "bravely",
      "briefly",
      "brightly",
      "briskly",
      "broadly",
      "busily",
      "calmly",
      "carefully",
      "carelessly",
      "cautiously",
      "certainly",
      "cheerfully",
      "clearly",
      "cleverly",
      "closely",
      "coaxingly",
      "commonly",
      "continually",
      "coolly",
      "correctly",
      "courageously",
      "crossly",
      "cruelly",
      "curiously",
      "daily",
      "daintily",
      "daringly",
      "dearly",
      "deceivingly",
      "deeply",
      "deliberately",
      "delightfully",
      "desperately",
      "determinedly",
      "diligently",
      "doubtfully",
      "dreamily",
      "eagerly",
      "easily",
      "elegantly",
      "energetically",
      "enormously",
      "equally",
      "especially",
      "even",
      "eventually",
      "exactly",
      "excitedly",
      "extremely",
      "fairly",
      "famously",
      "far",
      "fast",
      "fatally",
      "ferociously",
      "fervently",
      "fiercely",
      "fondly",
      "foolishly",
      "fortunately",
      "frankly",
      "frantically",
      "freely",
      "frightfully",
      "fully",
      "furiously",
      "generally",
      "generously",
      "gently",
      "gladly",
      "gracefully",
      "gratefully",
      "greatly",
      "greedily",
      "happily",
      "hard",
      "harshly",
      "hastily",
      "heartily",
      "heavily",
      "helpfully",
      "helplessly",
      "here",
      "highly",
      "honestly",
      "hopelessly",
      "hungrily",
      "hurriedly",
      "immediately",
      "inadequately",
      "increasingly",
      "innocently",
      "inquisitively",
      "instantly",
      "intensely",
      "interestingly",
      "inwardly",
      "irritably",
      "jealously",
      "jovially",
      "joyfully",
      "joyously",
      "jubilantly",
      "justly",
      "keenly",
      "kiddingly",
      "kindly",
      "knavishly",
      "knowingly",
      "knowledgeably",
      "lazily",
      "less",
      "lightly",
      "likely",
      "lively",
      "loftily",
      "longingly",
      "loosely",
      "loudly",
      "lovingly",
      "loyally",
      "madly",
      "majestically",
      "meaningfully",
      "mechanically",
      "merrily",
      "miserably",
      "mockingly",
      "more",
      "mortally",
      "mysteriously",
      "naturally",
      "nearly",
      "nervously",
      "never",
      "nicely",
      "noisily",
      "obediently",
      "oddly",
      "offensively",
      "officially",
      "only",
      "openly",
      "optimistically",
      "painfully",
      "patiently",
      "perfectly",
      "physically",
      "playfully",
      "politely",
      "poorly",
      "potentially",
      "powerfully",
      "promptly",
      "properly",
      "proudly",
      "punctually",
      "quaintly",
      "queerly",
      "questionably",
      "quicker",
      "quickly",
      "quietly",
      "quirkily",
      "quizzically",
      "rapidly",
      "rarely",
      "ravenously",
      "readily",
      "really",
      "reassuringly",
      "recklessly",
      "regularly",
      "reluctantly",
      "repeatedly",
      "restfully",
      "righteously",
      "rightfully",
      "roughly",
      "rudely",
      "sadly",
      "safely",
      "scarcely",
      "searchingly",
      "seemingly",
      "seldom",
      "selfishly",
      "seriously",
      "shakily",
      "sharply",
      "sheepishly",
      "shrilly",
      "shyly",
      "silently",
      "sleepily",
      "slowly",
      "smoothly",
      "softly",
      "solemnly",
      "sometimes",
      "soon",
      "speedily",
      "stealthily",
      "sternly",
      "strictly",
      "stubbornly",
      "stupidly",
      "suddenly",
      "supposedly",
      "surprisingly",
      "suspiciously",
      "sweetly",
      "swiftly",
      "sympathetically",
      "tensely",
      "terribly",
      "thankfully",
      "thoroughly",
      "thoughtfully",
      "tightly",
      "tomorrow",
      "tonight",
      "too",
      "tremendously",
      "truly",
      "truthfully",
      "ultimately",
      "unaccountably",
      "unbearably",
      "understandingly",
      "unexpectedly",
      "unfortunately",
      "unhappily",
      "unnecessarily",
      "unwillingly",
      "upbeat",
      "upright",
      "upward",
      "urgently",
      "usefully",
      "uselessly",
      "usually",
      "vacantly",
      "vaguely",
      "vainly",
      "valiantly",
      "vastly",
      "verbally",
      "viciously",
      "victoriously",
      "violently",
      "vivaciously",
      "voluntarily",
      "warmly",
      "wearily",
      "well",
      "wetly",
      "wholly",
      "wildly",
      "wisely",
      "wonderfully",
      "wrongly",
      "yearly",
      "youthfully"
    )
  )

# remove english Subordinating Conjunctions
docs <-
  tm::tm_map(
    docs,
    tm::removeWords,
    c(
      "after",
      "although",
      "as",
      "asif",
      "aslongas",
      "asmuchas",
      "assoonas",
      "asthough",
      "because",
      "before",
      "even",
      "evenif",
      "eventhough",
      "if",
      "ifonly",
      "ifwhen",
      "ifthen",
      "inasmuch",
      "inorderthat",
      "justas",
      "lest",
      "now",
      "nowsince",
      "nowthat",
      "nowwhen",
      "once",
      "provided",
      "providedthat",
      "ratherthat",
      "since",
      "sothat",
      "supposing",
      "than",
      "that",
      "though",
      "till",
      "unless",
      "until",
      "when",
      "whenever",
      "where",
      "whereas",
      "whereif",
      "wherever",
      "whether",
      "which",
      "while",
      "who",
      "whoever",
      "why"
    )
  )

# remove english modal-auxiliary-verbs
docs <-
  tm::tm_map(
    docs,
    tm::removeWords,
    c(
      "will",
      "would",
      "shall",
      "should",
      "can",
      "could",
      "may",
      "might",
      "must",
      "dare",
      "need",
      "used to",
      "ought to"
    )
  )

# remove english coordinating conjuction
docs <-
  tm::tm_map(docs,
             tm::removeWords,
             c("for",	"and",	"nor",	"but",	"or",	"yet",	"so"))

# remove english number
docs <-
  tm::tm_map(
    docs,
    tm::removeWords,
    c(
      "one",
      "two",
      "three",
      "four",
      "five",
      "six",
      "seven",
      "eight",
      "nine",
      "ten"
    )
  )

# remove other words currently found in scientific literature and other specific to this set of publications (e.g., the studies'sites names)
docs <-
  tm::tm_map(
    docs,
    tm::removeWords,
    c(
      "figure",
      "fig",
      "table",
      "first",
      "second",
      "third",
      "result",
      "significant",
      "observed",
      "also",
      "values",
      "according",
      "addition",
      "obtain",
      "using",
      "used",
      "allowed",
      "https",
      "Â°c",
      "france",
      "different",
      "<U+FB01>sh",
      "days",
      "previous",
      "rate",
      "level",
      "pbs",
      "lps",
      "control",
      "group",
      "multiple",
      "studie",
      "study",
      "total",
      "higher",
      "lower",
      "high",
      "low",
      "changes",
      "change",
      "increased",
      "decreased",
      "mean",
      "respectively",
      "potential",
      "affect",
      "due",
      "test",
      "number",
      "found",
      "axis",
      "xxx",
      "alone",
      "tion",
      "amix",
      "particularly",
      "average",
      "ausei",
      "riou",
      "arimas",
      "celfig",
      "relat",
      "represent",
      "measur",
      "observ",
      "antorpe",
      "allow",
      "petitjean",
      "jacquin",
      "celcab",
      "cantly",
      "cant",
      "non",
      "signi",
      "show",
      "suggest",
      "riem",
      "display",
      "determin",
      "con",
      "see",
      "account",
      "whole",
      "end",
      "caus",
      "supporting",
      "whatever",
      "inter",
      "plate",
      "bas",
      "especially",
      "including",
      "resulting",
      "indicate",
      "well",
      "follow",
      "consider",
      "general",
      "order",
      "present"
    )
  )

# remove remaining empty space
docs <- tm::tm_map(docs, tm::stripWhitespace)
# Text stemming
#docs <- tm::tm_map(docs, tm::stemDocument)

# construct words matrix
dtm <- tm::TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)

# manually correct some mistakes/approximation
d[which(d["word"] == "specie"), "word"] <- "species"
d[which(d["word"] == "exposure"), "freq"] <-
  d[which(d["word"] == "expos"), "freq"] + d[which(d["word"] == "exposure"), "freq"]
d <- d[-which(d["word"] == "expos"), ]
d[which(d["word"] == "physiology"), "freq"] <-
  d[which(d["word"] == "physiol"), "freq"] + d[which(d["word"] == "physiology"), "freq"]
d <- d[-which(d["word"] == "physiol"), ]
d[which(d["word"] == "metal"), "freq"] <-
  d[which(d["word"] == "tms"), "freq"] + d[which(d["word"] == "metal"), "freq"]
d <- d[-which(d["word"] == "tms"), ]
d[which(d["word"] == "injection"), "freq"] <-
  d[which(d["word"] == "inject"), "freq"] + d[which(d["word"] == "injection"), "freq"]
d <- d[-which(d["word"] == "inject"), ]
d[which(d["word"] == "decrease"), "freq"] <-
  d[which(d["word"] == "decreas"), "freq"] + d[which(d["word"] == "decrease"), "freq"]
d <- d[-which(d["word"] == "decreas"), ]
d[which(d["word"] == "increase"), "freq"] <-
  d[which(d["word"] == "increas"), "freq"] + d[which(d["word"] == "increase"), "freq"]
d <- d[-which(d["word"] == "increas"), ]
d[which(d["word"] == "combination"), "freq"] <-
  d[which(d["word"] == "combin"), "freq"] + d[which(d["word"] == "combination"), "freq"]
d <- d[-which(d["word"] == "combin"), ]
d <- d[-which(d["word"] == "combination"), ]
d[which(d["word"] == "contamination"), "freq"] <-
  d[which(d["word"] == "contaminat"), "freq"] + d[which(d["word"] == "contamination"), "freq"]
d <- d[-which(d["word"] == "contaminat"), ]
d[which(d["word"] == "environmental"), "freq"] <-
  d[which(d["word"] == "environ"), "freq"] + d[which(d["word"] == "environmental"), "freq"]
d <- d[-which(d["word"] == "environ"), ]
d[which(d["word"] == "comparison"), "freq"] <-
  d[which(d["word"] == "compar"), "freq"] + d[which(d["word"] == "comparison"), "freq"]
d <- d[-which(d["word"] == "compar"), ]
d[which(d["word"] == "depending"), "freq"] <-
  d[which(d["word"] == "depend"), "freq"] + d[which(d["word"] == "depending"), "freq"]
d <- d[-which(d["word"] == "depend"), ]
d[which(d["word"] == "activity"), "freq"] <-
  d[which(d["word"] == "activitie"), "freq"] + d[which(d["word"] == "activity"), "freq"]
d <- d[-which(d["word"] == "activitie"), ]
d[which(d["word"] == "maximum"), "freq"] <-
  d[which(d["word"] == "max"), "freq"] + d[which(d["word"] == "maximum"), "freq"]
d <- d[-which(d["word"] == "max"), ]

d[which(d["word"] == "identi"), "word"] <- "identity"
d[which(d["word"] == "min"), "word"] <- "minimum"
d[which(d["word"] == "biochem"), "word"] <- "biochemistry"

set.seed(1234)

grDevices::png(
  file = "./images/WordCloud_QP.png",
  width = 1200,
  height = 800,
  units = "px",
  res = 125,
  bg = "transparent"
)
wordcloud::wordcloud(
  words =  d$word[-1],
  freq = d$freq,
  min.freq = 10,
  max.words = 200,
  random.order = FALSE,
  rot.per = 0.25,
  colors = RColorBrewer::brewer.pal(6, "Dark2")
)
dev.off()

```

```{r WordCloudDisplay, echo=FALSE, results='asis', message=FALSE, warning=FALSE, fig.align = 'center', out.width="80%"}
knitr::include_graphics('images/WordCloud_QP.png', dpi = 150)
```

# BIO
<p class="plain-text">
I'm a postdoctoral researcher working on the effects of global changes on various organisms, such as micro-wasps <img src="https://icon-library.com/images/fly-icon/fly-icon-29.jpg" height="18px" width="18px" />, snails <img src="https://cdn-icons-png.flaticon.com/512/616/616636.png" height="18px" width="18px" />, and fish `r fontawesome::fa("fish", fill = "#003366")`.
</p> 
<p class="plain-text">
`r fontawesome::fa("circle-question", fill = "#358378")` More particularly, I'm investigating how stressors such as temperature changes `r fontawesome::fa("temperature-arrow-up", fill = "#660000")` `r fontawesome::fa("temperature-arrow-down", fill = "#99CCFF")`, pollution `r fontawesome::fa("biohazard", fill = "#FF9900")`, and pathogens `r fontawesome::fa("bacteria", fill = "#330000")` `r fontawesome::fa("viruses", fill = "#330000")` interact and affect populations persistence in the wild. Also, I'm trying to better understand how and why, some individuals can cope with such stressors while others cannot even survive `r fontawesome::fa("skull-crossbones", fill = "#000000")`? 
</p> 
<div class = "row">
<div class = "col-md-6">
<br/>
<p class="plain-text">
To tackle these questions, I'm measuring various organisms' traits across biological levels of organization, from the molecules (e.g., gene expression) to the cells (e.g., physiological responses such as oxidative stress, immune responses) and individuals (e.g., growth, behavior, survival). <br/><br/>
By gaining insight into intraspecific variability of responses to multiple stressors in the wild, I expect to better understand and predict global changes impacts on populations and ecosystems to improve management and conservation practices.
</p>
</div>

<div class = "col-md-6">
`r knitr::include_graphics('images/BiologicalLevelOrga.png', dpi = 500)`
</div>
</div>
<p class="plain-text">
Besides, I'm an `r fontawesome::fa("r-project", fill = "steelblue")` enthusiast, using it to: <br/>
`r fontawesome::fa("square-caret-right", fill = "#333333")` &ensp; Analyze data in a reliable and open framework. <br/>
`r fontawesome::fa("square-caret-right", fill = "#333333")` &ensp; Create the <a href="https://qpetitjean.github.io/MoveR/index.html"style="color:rgba(20, 130, 125, 1); font-style: italic; border-bottom: 0px; text-decoration: none; margin-right: 0px; margin-left: 0px;">MoveR package</a>. <br/>
`r fontawesome::fa("square-caret-right", fill = "#333333")` &ensp; And recently, create this website. <br/>
</p>
</div>
<div class="d-appendix">
</div>